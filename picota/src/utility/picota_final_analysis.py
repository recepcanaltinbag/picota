import os
import re
import pandas as pd
from ast import literal_eval

mapping_dir = "mapping"
scoring_dir = "scoring"
output_csv = "merged_summary.csv"


def load_sra_map():
    """selected_sra.csv dosyasÄ±nÄ± yÃ¼kler ve longâ†’short dict dÃ¶ndÃ¼rÃ¼r"""
    sra_map = {}
    try:
        df = pd.read_csv("selected_sra.csv")
        if "sra_short_id" in df.columns and "sra_long_id" in df.columns:
            # long â†’ short mapping
            sra_map = dict(zip(df["sra_long_id"], df["sra_short_id"]))
            print(f"âœ… {len(sra_map)} SRA eÅŸlemesi yÃ¼klendi (longâ†’short).")
        else:
            print("âš ï¸ selected_sra.csv sÃ¼tunlarÄ± eksik (sra_short_id, sra_long_id gerekli)")
    except FileNotFoundError:
        print("âš ï¸ selected_sra.csv bulunamadÄ±, mapping ID'ler doÄŸrudan kullanÄ±lacak.")
    return sra_map


def parse_mapping_file(file_path):
    """mapping dosyasÄ±ndan sadece pattern bilgilerini Ã§Ä±karÄ±r"""
    patterns = {}
    with open(file_path, "r") as f:
        lines = f.read().splitlines()

    for line in lines:
        line = line.strip()
        if not line or line.startswith("==="):
            continue

        if line.startswith(("SRR", "DRR", "ERR")):
            if ":" in line and "=" in line:
                right_part = line.split(":", 1)[1]
                pairs = [p.strip() for p in right_part.split(",") if "=" in p]
                for pair in pairs:
                    key, val = pair.split("=")
                    try:
                        patterns[key.strip()] = int(val.strip())
                    except ValueError:
                        pass
        elif line.startswith("{"):
            try:
                dict_data = literal_eval(line)
                if isinstance(dict_data, dict):
                    patterns.update(dict_data)
            except Exception:
                pass
    return patterns


def extract_cycle_id(filename):
    """dosya adÄ±ndan CycleID'yi Ã§Ä±kartÄ±r"""
    match = re.search(r"srr_summary_?(Cycle_.+?)_split\.fasta\.txt", filename)
    return match.group(1) if match else None


def collect_mapping_data(sra_map):
    mapping_data = []
    unknown_counter = 1

    for root, dirs, files in os.walk(mapping_dir):
        for file in files:
            if file.endswith(".txt") and "srr_summary" in file:
                path = os.path.join(root, file)
                patterns = parse_mapping_file(path)
                cycle_id = extract_cycle_id(file)

                # mapping klasÃ¶r adÄ± long id (Ã¶r: SRR5884790)
                long_id = os.path.basename(root)

                # eÅŸleÅŸen short id'yi bul
                srr_id = sra_map.get(long_id)
                if not srr_id:
                    srr_id = f"Unknown_SRR_{unknown_counter}"
                    unknown_counter += 1
                    print(f"âš ï¸ EÅŸleÅŸme bulunamadÄ±, long id: {long_id} -> {srr_id}")

                if cycle_id:
                    mapping_data.append({
                        "SRR_long": long_id,
                        "SRR": srr_id,  # short ID (scoring klasÃ¶rÃ¼ne denk)
                        "CycleID": cycle_id,
                        **patterns
                    })
                else:
                    print(f"âš ï¸ CycleID Ã§Ä±karÄ±lamadÄ±: {file}")

    df = pd.DataFrame(mapping_data)
    if df.empty:
        print("âš ï¸ mapping_df boÅŸ, SRR veya CycleID eksik olabilir.")
    else:
        print(f"âœ… {len(df)} mapping kaydÄ± toplandÄ±.")
    return df


def merge_with_scoring(mapping_df):
    merged = []
    for srr in mapping_df["SRR"].unique():
        mapping_subset = mapping_df[mapping_df["SRR"] == srr]
        scoring_path = os.path.join(scoring_dir, srr, "picota_final_tab")

        if not os.path.exists(scoring_path):
            print(f"âš ï¸ Skipped (scoring bulunamadÄ±): {srr}")
            continue

        try:
            scoring_df = pd.read_csv(scoring_path, sep="\t")
        except Exception as e:
            print(f"âš ï¸ Skipped (okuma hatasÄ±): {srr} ({e})")
            continue

        merged_df = pd.merge(mapping_subset, scoring_df,
                             on="CycleID", how="left",
                             suffixes=("_pattern", "_score"))
        merged.append(merged_df)

    if merged:
        return pd.concat(merged, ignore_index=True)
    else:
        return pd.DataFrame()


def main():
    print("ğŸ“¥ SRA ID eÅŸlemesi yÃ¼kleniyor...")
    sra_map = load_sra_map()

    print("ğŸ§© Mapping dosyalarÄ± toplanÄ±yor...")
    mapping_df = collect_mapping_data(sra_map)
    print(f"{len(mapping_df)} mapping kaydÄ± bulundu.")
    print(mapping_df.head())

    print("ğŸ”— Scoring dosyalarÄ±yla birleÅŸtiriliyor...")
    merged_df = merge_with_scoring(mapping_df)
    print(f"{len(merged_df)} toplam birleÅŸik kayÄ±t elde edildi.")

    merged_df.to_csv(output_csv, index=False)
    print(f"âœ… BirleÅŸik tablo '{output_csv}' olarak kaydedildi.")
    return merged_df


if __name__ == "__main__":
    df = main()

